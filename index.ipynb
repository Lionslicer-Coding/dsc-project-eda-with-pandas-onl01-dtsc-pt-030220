{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - EDA with Pandas Using the Boston Housing Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this section, you've learned a lot about importing, cleaning up, analyzing (using descriptive statistics) and visualizing data. In this more free-form project, you'll get a chance to practice all of these skills with the Boston Housing dataset, which contains housing values in the suburbs of Boston. The Boston housing data is commonly used by aspiring Data Scientists.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Perform a full exploratory data analysis process to gain insight about a dataset \n",
    "\n",
    "## Goals\n",
    "\n",
    "Use your data munging and visualization skills to conduct an exploratory analysis of the dataset below. At a minimum, this should include:\n",
    "\n",
    "* Loading the data (which is stored in the file `'train.csv'`) \n",
    "* Use built-in Python functions to explore measures of centrality and dispersion for at least 3 variables\n",
    "* Create *meaningful* subsets of the data using selection operations like `.loc`, `.iloc`, or related operations.   Explain why you used the chosen subsets and do this for three possible 2-way splits. State how you think the two measures of centrality and/or dispersion might be different for each subset of the data. Examples of potential splits:\n",
    "    - Create two new DataFrames based on your existing data, where one contains all the properties next to the Charles river, and the other one contains properties that aren't \n",
    "    - Create two new DataFrames based on a certain split for crime rate \n",
    "* Next, use histograms and scatter plots to see whether you observe differences for the subsets of the data. Make sure to use subplots so it is easy to compare the relationships.\n",
    "\n",
    "## Variable Descriptions\n",
    "\n",
    "This DataFrame contains the following columns:\n",
    "\n",
    "- `crim`: per capita crime rate by town  \n",
    "- `zn`: proportion of residential land zoned for lots over 25,000 sq.ft  \n",
    "- `indus`: proportion of non-retail business acres per town   \n",
    "- `chas`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)  \n",
    "- `nox`: nitrogen oxide concentration (parts per 10 million)   \n",
    "- `rm`: average number of rooms per dwelling   \n",
    "- `age`: proportion of owner-occupied units built prior to 1940  \n",
    "- `dis`: weighted mean of distances to five Boston employment centers   \n",
    "- `rad`: index of accessibility to radial highways   \n",
    "- `tax`: full-value property-tax rate per \\$10,000   \n",
    "- `ptratio`: pupil-teacher ratio by town    \n",
    "- `b`: 1000(Bk - 0.63)^2 where Bk is the proportion of African American individuals by town   \n",
    "- `lstat`: lower status of the population (percent)   \n",
    "- `medv`: median value of owner-occupied homes in $10000s \n",
    "  \n",
    "    \n",
    "**Source**\n",
    "- Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81–102.\n",
    "\n",
    "- Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley.\n",
    "\n",
    "**Important**: We mentioned in our data ethics lesson earlier that data can include offensive or inappropriate language at times. This is already becoming very apparent in the Boston Data, which includes a racial variable. \n",
    "Note that the Boston Housing data was constructed in the 1970’s, and is based on US census Data. On census.gov, you can read the following note:\n",
    "> \"Census statistics date back to 1790 and reflect the growth and change of the United States. Past census reports contain some terms that today's readers may consider obsolete and inappropriate. As part of our goal to be open and transparent with the public, we are improving access to all Census Bureau original publications and statistics, which serve as a guide to the nation's history.\"\n",
    "\n",
    "With that note, it is important to absolutely handle with care, and it is strongly adviced to _not_ use the racial variable when creating a predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importing pandas and setting it to display charts and graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin we need to import our data into a pandas dataframe that we can use to do our exploratory data analysis process. We will then preview the head and tail to verify the data has been imported properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
      "\n",
      "   ptratio       b  lstat  medv  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     18.7  394.63   2.94  33.4  \n",
      "3     18.7  396.90   5.33  36.2  \n",
      "4     15.2  395.60  12.43  22.9  \n",
      "      ID     crim   zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "328  500  0.17783  0.0   9.69     0  0.585  5.569  73.5  2.3999    6  391   \n",
      "329  502  0.06263  0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
      "330  503  0.04527  0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
      "331  504  0.06076  0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
      "332  506  0.04741  0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "328     19.2  395.77  15.10  17.5  \n",
      "329     21.0  391.99   9.67  22.4  \n",
      "330     21.0  396.90   9.08  20.6  \n",
      "331     21.0  396.90   5.64  23.9  \n",
      "332     21.0  396.90   7.88  11.9  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv') #read data file into pandas dataframe\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data set has been imported properly. We'll also get some summary metadata and info about the data in order to get an idea of some preliminary measures of centrality for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 15 columns):\n",
      "ID         333 non-null int64\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "b          333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 39.1 KB\n",
      "None\n",
      "               ID        crim          zn       indus        chas         nox  \\\n",
      "count  333.000000  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
      "mean   250.951952    3.360341   10.689189   11.293483    0.060060    0.557144   \n",
      "std    147.859438    7.352272   22.674762    6.998123    0.237956    0.114955   \n",
      "min      1.000000    0.006320    0.000000    0.740000    0.000000    0.385000   \n",
      "25%    123.000000    0.078960    0.000000    5.130000    0.000000    0.453000   \n",
      "50%    244.000000    0.261690    0.000000    9.900000    0.000000    0.538000   \n",
      "75%    377.000000    3.678220   12.500000   18.100000    0.000000    0.631000   \n",
      "max    506.000000   73.534100  100.000000   27.740000    1.000000    0.871000   \n",
      "\n",
      "               rm         age         dis         rad         tax     ptratio  \\\n",
      "count  333.000000  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
      "mean     6.265619   68.226426    3.709934    9.633634  409.279279   18.448048   \n",
      "std      0.703952   28.133344    1.981123    8.742174  170.841988    2.151821   \n",
      "min      3.561000    6.000000    1.129600    1.000000  188.000000   12.600000   \n",
      "25%      5.884000   45.400000    2.122400    4.000000  279.000000   17.400000   \n",
      "50%      6.202000   76.700000    3.092300    5.000000  330.000000   19.000000   \n",
      "75%      6.595000   93.800000    5.116700   24.000000  666.000000   20.200000   \n",
      "max      8.725000  100.000000   10.710300   24.000000  711.000000   21.200000   \n",
      "\n",
      "                b       lstat        medv  \n",
      "count  333.000000  333.000000  333.000000  \n",
      "mean   359.466096   12.515435   22.768769  \n",
      "std     86.584567    7.067781    9.173468  \n",
      "min      3.500000    1.730000    5.000000  \n",
      "25%    376.730000    7.180000   17.400000  \n",
      "50%    392.050000   10.970000   21.600000  \n",
      "75%    396.240000   16.420000   25.000000  \n",
      "max    396.900000   37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations, you've completed your first \"free form\" exploratory data analysis of a popular dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
